{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ff4a2f-4e91-4059-8516-044d69dc573a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b9a2ce-7c19-4c49-9d93-dcd34226d2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from sisyphy.data_processing.rhd_reading import load_file\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8c44bf-58ec-41b8-a674-226e69592a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"/Users/vigji/Downloads/barcode_testing_s3\")\n",
    "intan_path = data_path / \"intan\"\n",
    "\n",
    "data_intan = []\n",
    "time_intan = [[0]]\n",
    "for f in sorted(intan_path.glob(\"*.rhd\")):\n",
    "    print(f)\n",
    "    raw = load_file(f)\n",
    "    data_intan.append(raw[\"board_dig_in_data\"])\n",
    "    time_intan.append(raw[\"t_dig\"])  # + times_intan[-1][-1])\n",
    "data_intan = np.concatenate(data_intan, 1)\n",
    "time_intan = np.concatenate(time_intan[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46fe07d-f22d-475e-9f90-1f566f664866",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(data_intan[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9f5ff5-11b8-437c-8a74-eda9c44e17bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode_array = data_intan[1, :].astype(int) * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fcb88c-608e-4911-8a8a-8ddb911d71d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(barcode_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186f2904-13f4-466f-9f02-53da083c8149",
   "metadata": {},
   "outputs": [],
   "source": [
    "DURATION_THR = 15  # duration in ms below which one pulse is considered a wrapper\n",
    "BIT_WIDTH_MS = 30  # duration of each bit in ms\n",
    "WRAPPER_WIDTH_MS = 10  # duration of the wrapper in ms\n",
    "SIG_THR = 2.5  # threshold on signal for ON\n",
    "DIFF_THR = 0.5  # threshold on diff for transition\n",
    "FS_KHZ = 20.0  # sampling frequency in kHz\n",
    "N_BITS = 32\n",
    "\n",
    "wrap_width_pts = int(WRAPPER_WIDTH_MS * FS_KHZ)\n",
    "bit_width_pts = int(BIT_WIDTH_MS * FS_KHZ)\n",
    "duration_thr_pts = int(DURATION_THR * FS_KHZ)\n",
    "\n",
    "bit_base = 2 ** np.arange(N_BITS, dtype=np.int64)\n",
    "\n",
    "pulses_diff = np.diff(barcode_array)\n",
    "event_indexes = np.argwhere(np.abs(pulses_diff) > DIFF_THR)[:, 0]\n",
    "\n",
    "# Get on and off events:\n",
    "on_events = pulses_diff[event_indexes] > DIFF_THR\n",
    "off_events = ~on_events\n",
    "\n",
    "wrapper_select = (\n",
    "    on_events[:-1] & off_events[1:] & (np.diff(event_indexes) < duration_thr_pts)\n",
    ")\n",
    "wrapper_indexes = event_indexes[:-1][wrapper_select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5471f233-a6ed-423c-9ad5-cf18579c6787",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(pulses_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec36d0c-ca20-43be-80d6-873417490bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_base = 2 ** np.arange(N_BITS, dtype=np.int64)\n",
    "\n",
    "barcodes = []\n",
    "for wrapper_idx in wrapper_indexes[:-1:2]:\n",
    "    reading_start = wrapper_idx + wrap_width_pts * 2 + bit_width_pts // 2\n",
    "\n",
    "    # Read voltage level in the middle of the bins (#TODO maybe an average would be better):\n",
    "    bit_center_indexes = reading_start + np.arange(N_BITS) * bit_width_pts\n",
    "    bool_bits = barcode_array[bit_center_indexes] > SIG_THR\n",
    "    barcodes.append(sum(bit_base * bool_bits))\n",
    "\n",
    "barcodes = np.array(barcodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ce9119-128a-45ed-a059-6667f12c3219",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcodes_times = time_intan[wrapper_indexes[:-1:2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6aa224-8bf2-41ed-a44a-4eccfb104965",
   "metadata": {},
   "source": [
    "### load csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c155c9-1116-4b1a-ac06-76cceb76a1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f29b2c-f7a0-4904-bf44-2078ea6e4cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tstamps = pd.read_csv(next(data_path.glob(\"*timestamps.txt\")))\n",
    "tmouse = pd.read_csv(next(data_path.glob(\"*mouse.txt\")))\n",
    "# tstamps[\"t_ns_code\"] = (tstamps[\"t_ns_code\"] - tstamps[\"t_ns_code\"][0]) / 1e9\n",
    "\n",
    "# t_0_sp = tmouse[\"t_ns\"][0]\n",
    "# tstamps[\"t_ns\"] = (tstamps[\"t_ns\"] - t_0_sp) / 1e9\n",
    "# tmouse[\"t_ns\"] = (tmouse[\"t_ns\"] - t_0_sp) / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be536b71-ccc9-48bf-9119-fcf065f3c46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "intan_barcodes = pd.DataFrame(dict(t_s=barcodes_times), index=barcodes)\n",
    "tstamps = tstamps.set_index(\"code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dbbc1e-e27e-4904-8a1b-6576f66f8c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "\n",
    "for bcode in tstamps.index:\n",
    "    pairs.append((tstamps.loc[bcode, \"t_ns_code\"], intan_barcodes.loc[bcode, \"t_s\"]))\n",
    "\n",
    "pairs = np.array(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7fb749-b8fe-4516-a030-3edaef1e54a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = pairs - pairs[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c71ffd-0226-4d1c-998f-bbb2c0777061",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(2, 1, sharex=True, figsize=(4, 3))\n",
    "x = np.arange(-6, 6, 0.2)\n",
    "for arr, ax in zip([intan_barcodes[\"t_s\"], tstamps[\"t_ns_code\"] / 1e9], axs):\n",
    "    ax.hist((np.diff(arr) - np.mean(np.diff(arr))) * 1000, x, histtype=\"step\")\n",
    "    sd = np.std((np.diff(arr) - np.mean(np.diff(arr))) * 1000)\n",
    "    # ax.text(0, 50, sd)\n",
    "    ax.set(ylabel=\"Count\")\n",
    "ax.set(xlabel=\"Jitter (ms)\")\n",
    "plt.show()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ecf07c-2b8b-4558-81a9-d7efe9cc120e",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_numpy_barcode = intan_barcodes.index.values  # main_numpy_data[barcodes_row, :]\n",
    "secondary_numpy_barcode = tstamps.index.values  # secondary_numpy_data[barcodes_row, :]\n",
    "\n",
    "main_numpy_timestamp = intan_barcodes[\n",
    "    \"t_s\"\n",
    "].values  # main_numpy_data[barcode_timestamps_row, :]\n",
    "secondary_numpy_timestamp = tstamps[\n",
    "    \"t_ns_code\"\n",
    "].values  # secondary_numpy_data[barcode_timestamps_row, :]\n",
    "\n",
    "# Pull the index values from barcodes shared by both groups of data\n",
    "shared_barcodes, main_index, second_index = np.intersect1d(\n",
    "    main_numpy_barcode, secondary_numpy_barcode, return_indices=True\n",
    ")\n",
    "\n",
    "# Use main_index and second_index arrays to extract related timestamps\n",
    "main_shared_barcode_times = main_numpy_timestamp[main_index]\n",
    "secondary_shared_barcode_times = secondary_numpy_timestamp[second_index]\n",
    "\n",
    "# Determine slope (m) between main/secondary timestamps\n",
    "m = (main_shared_barcode_times[-1] - main_shared_barcode_times[0]) / (\n",
    "    secondary_shared_barcode_times[-1] - secondary_shared_barcode_times[0]\n",
    ")\n",
    "# Determine offset (b) between main and secondary barcode timestamps\n",
    "b = main_shared_barcode_times[0] - secondary_shared_barcode_times[0] * m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cd8568-521a-4240-bcbe-7c64d903b0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_signal = tmouse.copy()\n",
    "mouse_signal = mouse_signal.set_index(\"t_ns\").drop(\"Unnamed: 0\", axis=1)\n",
    "mouse_signal.index = pd.to_datetime(mouse_signal.index, unit=\"ns\")\n",
    "mouse_signal.resample(\"1ms\").mean().interpolate()\n",
    "mouse_signal.index = mouse_signal.index.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73230f8f-305f-46e3-8db1-0513e96d720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_intan = 8000\n",
    "\n",
    "\n",
    "def _convolve(sig, fs, kernel_size_s=0.05):\n",
    "    kernel_size_pts = int(kernel_size_s * fs)\n",
    "    print(kernel_size_pts)\n",
    "    kernel = np.ones(kernel_size_pts) / kernel_size_pts\n",
    "    return np.convolve(sig, kernel, mode=\"same\")  # [:len(sig) + 1]\n",
    "\n",
    "\n",
    "sig_intan = _convolve(np.diff(data_intan[5:7, :], axis=1).sum(0), 8000)\n",
    "\n",
    "converted_tscale = mouse_signal.index * m + b\n",
    "sig_mouse = np.abs(mouse_signal[[\"pitch\", \"roll\", \"yaw\"]].values.mean(1))\n",
    "sig_mouse = _convolve(sig_mouse, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729ff998-d7fe-4345-bacc-d5ac867be1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanpercentile(sig_intan, 99.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb9d9de-19ed-4358-9425-ef3fc808e720",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(8, 3))\n",
    "ax.plot(\n",
    "    converted_tscale, sig_mouse / np.percentile(sig_mouse, 99.9), label=\"Mouse speed\"\n",
    ")\n",
    "slice_t = slice(64562000, 66662000)\n",
    "ax.plot(\n",
    "    time_intan[slice_t],\n",
    "    sig_intan[slice_t] / np.nanpercentile(sig_intan, 99.9),\n",
    "    label=\"Intan rotarod speed\",\n",
    ")\n",
    "ax.set(xlabel=\"Recording time (s)\", xlim=(3271, 3274))\n",
    "ax.legend(frameon=False)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7a1fc2-98e7-4105-951e-69d3c6feca1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(time_intan) / 22000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20034b43-4bde-4757-81e9-221a3a7c5c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_intan[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69d5abc-ff17-4682-afc1-d120b153513e",
   "metadata": {},
   "outputs": [],
   "source": [
    "3281 * 22000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1d2ae1-f746-4a1f-9e42-2e1155a94d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5a44ae-b6b6-4c3b-841d-0a9be02a54cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "secondary_data_original[:, convert_timestamp_column] = (\n",
    "    secondary_data_original * secondary_sample_rate * m + b\n",
    ")\n",
    "\n",
    "# Clean up conversion of values to nearest whole number\n",
    "# print(\"Total number of index values: \", len(secondary_data_converted[:,convert_timestamp_column]))\n",
    "value = secondary_data_converted[index, convert_timestamp_column]\n",
    "secondary_data_converted[convert_timestamp_column] = value.astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae2181d-6d9f-4b47-853e-8cb9e566b3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  Optogenetics and Neural Engineering Core ONE Core\n",
    "  University of Colorado, School of Medicine\n",
    "  31.Oct.2021\n",
    "  See bit.ly/onecore for more information, including a more detailed write up.\n",
    "  alignment_barcodes.py\n",
    "################################################################################\n",
    "  This code takes two Numpy files (\"main\" and \"secondary\" data) that contain the \n",
    "  timestamp and barcode values collected using \"extraction_barcodes.py\", and \n",
    "  finds the linear conversion variables needed to align the timestamps. Then it\n",
    "  takes the original (or .npy converted) secondary data file, applies the linear\n",
    "  conversion to its timestamp column, and outputs this data as a Numpy (.npy) or\n",
    "  CSV (.csv) file into a chosen directory.\n",
    "################################################################################\n",
    "  USER INPUTS EXPLAINED:\n",
    "\n",
    "  Input Variables:\n",
    "  = main_sample_rate = (int) The sampling rate (in Hz) of the \"main\" DAQ, to\n",
    "                       which the secondary data will be aligned.\n",
    "  = secondary_sample_rate = (int) The sampling rate (in Hz) of the \"secondary\"\n",
    "                            DAQ, which will be aligned to the \"main\" DAQ.\n",
    "  = convert_timestamp_column = (int) The timestamp column in the original \n",
    "                               \"secondary\" data file; this will be converted to\n",
    "                               match the timestamps in the original \"main\" data.\n",
    "\n",
    "  Output Variables: \n",
    "  = alignment_name = (str) The name of the file(s) in which the output will be \n",
    "                     saved in the chosen directory.\n",
    "  = save_npy = (bool) Set to \"True\" to save the aligned data as a .npy file.\n",
    "  = save_csv = (bool) Set to \"True\" to save the aligned data as a .csv file.\n",
    "  \n",
    "################################################################################\n",
    "  References\n",
    "\n",
    "\"\"\"\n",
    "#######################\n",
    "### Imports Section ###\n",
    "#######################\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from tkinter.filedialog import askdirectory, askopenfilename\n",
    "\n",
    "################################################################################\n",
    "############################ USER INPUT SECTION ################################\n",
    "################################################################################\n",
    "\n",
    "# Input variables\n",
    "main_sample_rate = 30000  # Expected sample rate of main data, in Hz\n",
    "secondary_sample_rate = 2000  # Expected sample rate of secondary data, in Hz\n",
    "convert_timestamp_column = 0  # Column that timestamps are located in secondary data\n",
    "\n",
    "# Output variables\n",
    "alignment_name = \"LabJackAlignedToNeuroPixelTest\"  # Name of output file.\n",
    "save_npy = False  # Save output file as a .npy file\n",
    "save_csv = False  # Save output file as a .csv file\n",
    "\n",
    "################################################################################\n",
    "############################ END OF USER INPUT #################################\n",
    "################################################################################\n",
    "\n",
    "##########################################\n",
    "### Select Files for Barcode Alignment ###\n",
    "##########################################\n",
    "\n",
    "# Have user select files to be used.\n",
    "# Main data's barcodes input file:\n",
    "try:\n",
    "    main_dir_and_name = Path(askopenfilename(title=\"Select Main Data Barcodes File\"))\n",
    "except:\n",
    "    print(\"No Main Data Barcodes File Chosen\")\n",
    "    sys.exit()\n",
    "# Secondary data's barcodes input file\n",
    "try:\n",
    "    secondary_dir_and_name = Path(\n",
    "        askopenfilename(title=\"Select Secondary Data Barcodes File\")\n",
    "    )\n",
    "except:\n",
    "    print(\"No Secondary Data Barcodes File Chosen\")\n",
    "    sys.exit()\n",
    "# Secondary data file to be aligned with main data.\n",
    "try:\n",
    "    secondary_raw_data = Path(\n",
    "        askopenfilename(title=\"Select Secondary Data File to Align\")\n",
    "    )\n",
    "except:\n",
    "    print(\"No Secondary Data File to Align Chosen\")\n",
    "    sys.exit()\n",
    "\n",
    "# Try to load the selected files; if they fail, inform the user.\n",
    "try:\n",
    "    main_numpy_data = np.load(main_dir_and_name)\n",
    "except:\n",
    "    main_numpy_data = \"\"\n",
    "    print(\"Main .npy file not located/failed to load; please check the filepath\")\n",
    "\n",
    "try:\n",
    "    secondary_numpy_data = np.load(secondary_dir_and_name)\n",
    "except:\n",
    "    secondary_numpy_data = \"\"\n",
    "    print(\"Secondary .npy file not located/failed to load; please check the filepath\")\n",
    "\n",
    "try:\n",
    "    secondary_data_original = np.load(secondary_raw_data)\n",
    "except:\n",
    "    secondary_data_original = \"\"\n",
    "    print(\n",
    "        \"Data file to be aligned not located/failed to load; please check your filepath\"\n",
    "    )\n",
    "\n",
    "# Have user select folder into which aligned data will be saved; if no format\n",
    "# selected, inform the user.\n",
    "if save_npy or save_csv or save_dat:\n",
    "    try:\n",
    "        alignment_dir = Path(askdirectory(title=\"Select Folder to Save Aligned Data\"))\n",
    "    except:\n",
    "        print(\"No Output Directory Selected\")\n",
    "        sys.exit()\n",
    "else:\n",
    "    print(\"Aligned data will not be saved to file in any format.\")\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "### Extract Barcodes and Index Values, then Calculate Linear Variables ###\n",
    "##########################################################################\n",
    "\n",
    "# Pull the barcode row from the data. 1st column is timestamps, second is barcodes\n",
    "barcode_timestamps_row = (\n",
    "    0  # Same for both main and secondary, because we used our own code\n",
    ")\n",
    "barcodes_row = 1  # Same for both main and secondary\n",
    "\n",
    "main_numpy_barcode = main_numpy_data[barcodes_row, :]\n",
    "secondary_numpy_barcode = secondary_numpy_data[barcodes_row, :]\n",
    "\n",
    "main_numpy_timestamp = main_numpy_data[barcode_timestamps_row, :]\n",
    "secondary_numpy_timestamp = secondary_numpy_data[barcode_timestamps_row, :]\n",
    "\n",
    "# Pull the index values from barcodes shared by both groups of data\n",
    "shared_barcodes, main_index, second_index = np.intersect1d(\n",
    "    main_numpy_barcode, secondary_numpy_barcode, return_indices=True\n",
    ")\n",
    "# Note: To intersect more than two arrays, use functools.reduce\n",
    "\n",
    "# Use main_index and second_index arrays to extract related timestamps\n",
    "main_shared_barcode_times = main_numpy_timestamp[main_index]\n",
    "secondary_shared_barcode_times = secondary_numpy_timestamp[second_index]\n",
    "\n",
    "# Determine slope (m) between main/secondary timestamps\n",
    "m = (main_shared_barcode_times[-1] - main_shared_barcode_times[0]) / (\n",
    "    secondary_shared_barcode_times[-1] - secondary_shared_barcode_times[0]\n",
    ")\n",
    "# Determine offset (b) between main and secondary barcode timestamps\n",
    "b = main_shared_barcode_times[0] - secondary_shared_barcode_times[0] * m\n",
    "\n",
    "print(\"Linear conversion from secondary timestamps to main:\\ny = \", m, \"x + \", b)\n",
    "\n",
    "##################################################################\n",
    "### Apply Linear Conversion to Secondary Data (in .npy Format) ###\n",
    "##################################################################\n",
    "\n",
    "secondary_data_original[:, convert_timestamp_column] = (\n",
    "    secondary_data_original[:, convert_timestamp_column] * secondary_sample_rate * m + b\n",
    ")\n",
    "secondary_data_converted = secondary_data_original  # To show conversion complete.\n",
    "\n",
    "# Clean up conversion of values to nearest whole number\n",
    "# print(\"Total number of index values: \", len(secondary_data_converted[:,convert_timestamp_column]))\n",
    "for index in range(0, len(secondary_data_converted[:, convert_timestamp_column])):\n",
    "    value = secondary_data_converted[index, convert_timestamp_column]\n",
    "    rounded_val = value.astype(\"int\")\n",
    "    secondary_data_converted[index, convert_timestamp_column] = rounded_val\n",
    "\n",
    "################################################################\n",
    "### Print out final output and save to chosen file format(s) ###\n",
    "################################################################\n",
    "\n",
    "# Test to see output here:\n",
    "print(\"Final output for LJ Data:\\n\", secondary_data_converted)\n",
    "\n",
    "time_now = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "if save_npy:\n",
    "    output_file = alignment_dir / (alignment_name + time_now)\n",
    "    np.save(output_file, secondary_data_converted)\n",
    "\n",
    "if save_csv:\n",
    "    output_file = alignment_dir / (alignment_name + time_now + \".csv\")\n",
    "    np.savetxt(output_file, secondary_data_converted, delimiter=\",\", fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1ee236-f81e-4650-b3b9-524781b14ab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1df987a-d800-4832-b060-eaffa7e972f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
